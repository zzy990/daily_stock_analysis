# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - ä¸»è°ƒåº¦ç¨‹åº
===================================

èŒè´£ï¼š
1. åè°ƒå„æ¨¡å—å®Œæˆè‚¡ç¥¨åˆ†ææµç¨‹
2. å®ç°ä½å¹¶å‘çš„çº¿ç¨‹æ± è°ƒåº¦
3. å…¨å±€å¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿å•è‚¡å¤±è´¥ä¸å½±å“æ•´ä½“
4. æä¾›å‘½ä»¤è¡Œå…¥å£

ä½¿ç”¨æ–¹å¼ï¼š
    python main.py              # æ­£å¸¸è¿è¡Œ
    python main.py --debug      # è°ƒè¯•æ¨¡å¼
    python main.py --dry-run    # ä»…è·å–æ•°æ®ä¸åˆ†æ

äº¤æ˜“ç†å¿µï¼ˆå·²èå…¥åˆ†æï¼‰ï¼š
- ä¸¥è¿›ç­–ç•¥ï¼šä¸è¿½é«˜ï¼Œä¹–ç¦»ç‡ > 5% ä¸ä¹°å…¥
- è¶‹åŠ¿äº¤æ˜“ï¼šåªåš MA5>MA10>MA20 å¤šå¤´æ’åˆ—
- æ•ˆç‡ä¼˜å…ˆï¼šå…³æ³¨ç­¹ç é›†ä¸­åº¦å¥½çš„è‚¡ç¥¨
- ä¹°ç‚¹åå¥½ï¼šç¼©é‡å›è¸© MA5/MA10 æ”¯æ’‘
"""
import os
from src.config import setup_env
setup_env()

# ä»£ç†é…ç½® - é€šè¿‡ USE_PROXY ç¯å¢ƒå˜é‡æ§åˆ¶ï¼Œé»˜è®¤å…³é—­
# GitHub Actions ç¯å¢ƒè‡ªåŠ¨è·³è¿‡ä»£ç†é…ç½®
if os.getenv("GITHUB_ACTIONS") != "true" and os.getenv("USE_PROXY", "false").lower() == "true":
    # æœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œå¯ç”¨ä»£ç†ï¼ˆå¯åœ¨ .env ä¸­é…ç½® PROXY_HOST å’Œ PROXY_PORTï¼‰
    proxy_host = os.getenv("PROXY_HOST", "127.0.0.1")
    proxy_port = os.getenv("PROXY_PORT", "10809")
    proxy_url = f"http://{proxy_host}:{proxy_port}"
    os.environ["http_proxy"] = proxy_url
    os.environ["https_proxy"] = proxy_url

import argparse
import logging
import sys
import time
import uuid
from datetime import datetime, timezone, timedelta
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Optional
from src.feishu_doc import FeishuDocManager

from src.config import get_config, Config
from src.notification import NotificationService
from src.core.pipeline import StockAnalysisPipeline
from src.core.market_review import run_market_review
from src.search_service import SearchService
from src.analyzer import GeminiAnalyzer

# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'


def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿï¼ˆåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼‰
    
    Args:
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        log_dir: æ—¥å¿—æ–‡ä»¶ç›®å½•
    """
    level = logging.DEBUG if debug else logging.INFO
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    # æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆæŒ‰æ—¥æœŸåˆ†æ–‡ä»¶ï¼‰
    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"stock_analysis_{today_str}.log"
    debug_log_file = log_path / f"stock_analysis_debug_{today_str}.log"
    
    # åˆ›å»ºæ ¹ logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)  # æ ¹ logger è®¾ä¸º DEBUGï¼Œç”± handler æ§åˆ¶è¾“å‡ºçº§åˆ«
    
    # Handler 1: æ§åˆ¶å°è¾“å‡º
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)
    
    # Handler 2: å¸¸è§„æ—¥å¿—æ–‡ä»¶ï¼ˆINFO çº§åˆ«ï¼Œ10MB è½®è½¬ï¼‰
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(file_handler)
    
    # Handler 3: è°ƒè¯•æ—¥å¿—æ–‡ä»¶ï¼ˆDEBUG çº§åˆ«ï¼ŒåŒ…å«æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ï¼‰
    debug_handler = RotatingFileHandler(
        debug_log_file,
        maxBytes=50 * 1024 * 1024,  # 50MB
        backupCount=3,
        encoding='utf-8'
    )
    debug_handler.setLevel(logging.DEBUG)
    debug_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(debug_handler)
    
    # é™ä½ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('sqlalchemy').setLevel(logging.WARNING)
    logging.getLogger('google').setLevel(logging.WARNING)
    logging.getLogger('httpx').setLevel(logging.WARNING)
    
    logging.info(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œæ—¥å¿—ç›®å½•: {log_path.absolute()}")
    logging.info(f"å¸¸è§„æ—¥å¿—: {log_file}")
    logging.info(f"è°ƒè¯•æ—¥å¿—: {debug_log_file}")


logger = logging.getLogger(__name__)


def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  python main.py                    # æ­£å¸¸è¿è¡Œ
  python main.py --debug            # è°ƒè¯•æ¨¡å¼
  python main.py --dry-run          # ä»…è·å–æ•°æ®ï¼Œä¸è¿›è¡Œ AI åˆ†æ
  python main.py --stocks 600519,000001  # æŒ‡å®šåˆ†æç‰¹å®šè‚¡ç¥¨
  python main.py --no-notify        # ä¸å‘é€æ¨é€é€šçŸ¥
  python main.py --single-notify    # å¯ç”¨å•è‚¡æ¨é€æ¨¡å¼ï¼ˆæ¯åˆ†æå®Œä¸€åªç«‹å³æ¨é€ï¼‰
  python main.py --schedule         # å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼
  python main.py --market-review    # ä»…è¿è¡Œå¤§ç›˜å¤ç›˜
        '''
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ—¥å¿—'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ä»…è·å–æ•°æ®ï¼Œä¸è¿›è¡Œ AI åˆ†æ'
    )
    
    parser.add_argument(
        '--stocks',
        type=str,
        help='æŒ‡å®šè¦åˆ†æçš„è‚¡ç¥¨ä»£ç ï¼Œé€—å·åˆ†éš”ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    parser.add_argument(
        '--no-notify',
        action='store_true',
        help='ä¸å‘é€æ¨é€é€šçŸ¥'
    )
    
    parser.add_argument(
        '--single-notify',
        action='store_true',
        help='å¯ç”¨å•è‚¡æ¨é€æ¨¡å¼ï¼šæ¯åˆ†æå®Œä¸€åªè‚¡ç¥¨ç«‹å³æ¨é€ï¼Œè€Œä¸æ˜¯æ±‡æ€»æ¨é€'
    )
    
    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help='å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰'
    )
    
    parser.add_argument(
        '--schedule',
        action='store_true',
        help='å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼ï¼Œæ¯æ—¥å®šæ—¶æ‰§è¡Œ'
    )
    
    parser.add_argument(
        '--market-review',
        action='store_true',
        help='ä»…è¿è¡Œå¤§ç›˜å¤ç›˜åˆ†æ'
    )
    
    parser.add_argument(
        '--no-market-review',
        action='store_true',
        help='è·³è¿‡å¤§ç›˜å¤ç›˜åˆ†æ'
    )
    
    parser.add_argument(
        '--webui',
        action='store_true',
        help='å¯åŠ¨æœ¬åœ°é…ç½® WebUI'
    )
    
    parser.add_argument(
        '--webui-only',
        action='store_true',
        help='ä»…å¯åŠ¨ WebUI æœåŠ¡ï¼Œä¸è‡ªåŠ¨æ‰§è¡Œåˆ†æï¼ˆé€šè¿‡ /analysis API æ‰‹åŠ¨è§¦å‘ï¼‰'
    )

    parser.add_argument(
        '--no-context-snapshot',
        action='store_true',
        help='ä¸ä¿å­˜åˆ†æä¸Šä¸‹æ–‡å¿«ç…§'
    )
    
    return parser.parse_args()


def run_full_analysis(
    config: Config,
    args: argparse.Namespace,
    stock_codes: Optional[List[str]] = None
):
    """
    æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼ˆä¸ªè‚¡ + å¤§ç›˜å¤ç›˜ï¼‰
    
    è¿™æ˜¯å®šæ—¶ä»»åŠ¡è°ƒç”¨çš„ä¸»å‡½æ•°
    """
    try:
        # å‘½ä»¤è¡Œå‚æ•° --single-notify è¦†ç›–é…ç½®ï¼ˆ#55ï¼‰
        if getattr(args, 'single_notify', False):
            config.single_stock_notify = True
        
        # åˆ›å»ºè°ƒåº¦å™¨
        save_context_snapshot = None
        if getattr(args, 'no_context_snapshot', False):
            save_context_snapshot = False
        query_id = uuid.uuid4().hex
        pipeline = StockAnalysisPipeline(
            config=config,
            max_workers=args.workers,
            query_id=query_id,
            query_source="cli",
            save_context_snapshot=save_context_snapshot
        )
        
        # 1. è¿è¡Œä¸ªè‚¡åˆ†æ
        results = pipeline.run(
            stock_codes=stock_codes,
            dry_run=args.dry_run,
            send_notification=not args.no_notify
        )

        # Issue #128: åˆ†æé—´éš” - åœ¨ä¸ªè‚¡åˆ†æå’Œå¤§ç›˜åˆ†æä¹‹é—´æ·»åŠ å»¶è¿Ÿ
        analysis_delay = getattr(config, 'analysis_delay', 0)
        if analysis_delay > 0 and config.market_review_enabled and not args.no_market_review:
            logger.info(f"ç­‰å¾… {analysis_delay} ç§’åæ‰§è¡Œå¤§ç›˜å¤ç›˜ï¼ˆé¿å…APIé™æµï¼‰...")
            time.sleep(analysis_delay)

        # 2. è¿è¡Œå¤§ç›˜å¤ç›˜ï¼ˆå¦‚æœå¯ç”¨ä¸”ä¸æ˜¯ä»…ä¸ªè‚¡æ¨¡å¼ï¼‰
        market_report = ""
        if config.market_review_enabled and not args.no_market_review:
            # åªè°ƒç”¨ä¸€æ¬¡ï¼Œå¹¶è·å–ç»“æœ
            review_result = run_market_review(
                notifier=pipeline.notifier,
                analyzer=pipeline.analyzer,
                search_service=pipeline.search_service,
                send_notification=not args.no_notify
            )
            # å¦‚æœæœ‰ç»“æœï¼Œèµ‹å€¼ç»™ market_report ç”¨äºåç»­é£ä¹¦æ–‡æ¡£ç”Ÿæˆ
            if review_result:
                market_report = review_result
        
        # è¾“å‡ºæ‘˜è¦
        if results:
            logger.info("\n===== åˆ†æç»“æœæ‘˜è¦ =====")
            for r in sorted(results, key=lambda x: x.sentiment_score, reverse=True):
                emoji = r.get_emoji()
                logger.info(
                    f"{emoji} {r.name}({r.code}): {r.operation_advice} | "
                    f"è¯„åˆ† {r.sentiment_score} | {r.trend_prediction}"
                )
        
        logger.info("\nä»»åŠ¡æ‰§è¡Œå®Œæˆ")

        # === æ–°å¢ï¼šç”Ÿæˆé£ä¹¦äº‘æ–‡æ¡£ ===
        try:
            feishu_doc = FeishuDocManager()
            if feishu_doc.is_configured() and (results or market_report):
                logger.info("æ­£åœ¨åˆ›å»ºé£ä¹¦äº‘æ–‡æ¡£...")

                # 1. å‡†å¤‡æ ‡é¢˜ "01-01 13:01å¤§ç›˜å¤ç›˜"
                tz_cn = timezone(timedelta(hours=8))
                now = datetime.now(tz_cn)
                doc_title = f"{now.strftime('%Y-%m-%d %H:%M')} å¤§ç›˜å¤ç›˜"

                # 2. å‡†å¤‡å†…å®¹ (æ‹¼æ¥ä¸ªè‚¡åˆ†æå’Œå¤§ç›˜å¤ç›˜)
                full_content = ""

                # æ·»åŠ å¤§ç›˜å¤ç›˜å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if market_report:
                    full_content += f"# ğŸ“ˆ å¤§ç›˜å¤ç›˜\n\n{market_report}\n\n---\n\n"

                # æ·»åŠ ä¸ªè‚¡å†³ç­–ä»ªè¡¨ç›˜ï¼ˆä½¿ç”¨ NotificationService ç”Ÿæˆï¼‰
                if results:
                    dashboard_content = pipeline.notifier.generate_dashboard_report(results)
                    full_content += f"# ğŸš€ ä¸ªè‚¡å†³ç­–ä»ªè¡¨ç›˜\n\n{dashboard_content}"

                # 3. åˆ›å»ºæ–‡æ¡£
                doc_url = feishu_doc.create_daily_doc(doc_title, full_content)
                if doc_url:
                    logger.info(f"é£ä¹¦äº‘æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {doc_url}")
                    # å¯é€‰ï¼šå°†æ–‡æ¡£é“¾æ¥ä¹Ÿæ¨é€åˆ°ç¾¤é‡Œ
                    if not args.no_notify:
                        pipeline.notifier.send(f"[{now.strftime('%Y-%m-%d %H:%M')}] å¤ç›˜æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {doc_url}")

        except Exception as e:
            logger.error(f"é£ä¹¦æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
        
    except Exception as e:
        logger.exception(f"åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥: {e}")


def start_bot_stream_clients(config: Config) -> None:
    """Start bot stream clients when enabled in config."""
    # å¯åŠ¨é’‰é’‰ Stream å®¢æˆ·ç«¯
    if config.dingtalk_stream_enabled:
        try:
            from bot.platforms import start_dingtalk_stream_background, DINGTALK_STREAM_AVAILABLE
            if DINGTALK_STREAM_AVAILABLE:
                if start_dingtalk_stream_background():
                    logger.info("[Main] Dingtalk Stream client started in background.")
                else:
                    logger.warning("[Main] Dingtalk Stream client failed to start.")
            else:
                logger.warning("[Main] Dingtalk Stream enabled but SDK is missing.")
                logger.warning("[Main] Run: pip install dingtalk-stream")
        except Exception as exc:
            logger.error(f"[Main] Failed to start Dingtalk Stream client: {exc}")

    # å¯åŠ¨é£ä¹¦ Stream å®¢æˆ·ç«¯
    if getattr(config, 'feishu_stream_enabled', False):
        try:
            from bot.platforms import start_feishu_stream_background, FEISHU_SDK_AVAILABLE
            if FEISHU_SDK_AVAILABLE:
                if start_feishu_stream_background():
                    logger.info("[Main] Feishu Stream client started in background.")
                else:
                    logger.warning("[Main] Feishu Stream client failed to start.")
            else:
                logger.warning("[Main] Feishu Stream enabled but SDK is missing.")
                logger.warning("[Main] Run: pip install lark-oapi")
        except Exception as exc:
            logger.error(f"[Main] Failed to start Feishu Stream client: {exc}")


def main() -> int:
    """
    ä¸»å…¥å£å‡½æ•°
    
    Returns:
        é€€å‡ºç ï¼ˆ0 è¡¨ç¤ºæˆåŠŸï¼‰
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # åŠ è½½é…ç½®ï¼ˆåœ¨è®¾ç½®æ—¥å¿—å‰åŠ è½½ï¼Œä»¥è·å–æ—¥å¿—ç›®å½•ï¼‰
    config = get_config()
    
    # é…ç½®æ—¥å¿—ï¼ˆè¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼‰
    setup_logging(debug=args.debug, log_dir=config.log_dir)
    
    logger.info("=" * 60)
    logger.info("Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ å¯åŠ¨")
    logger.info(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # éªŒè¯é…ç½®
    warnings = config.validate()
    for warning in warnings:
        logger.warning(warning)
    
    # è§£æè‚¡ç¥¨åˆ—è¡¨
    stock_codes = None
    if args.stocks:
        stock_codes = [code.strip() for code in args.stocks.split(',') if code.strip()]
        logger.info(f"ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨: {stock_codes}")
    
    # === å¯åŠ¨ WebUI (å¦‚æœå¯ç”¨) ===
    # ä¼˜å…ˆçº§: å‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶
    start_webui = (args.webui or args.webui_only or config.webui_enabled) and os.getenv("GITHUB_ACTIONS") != "true"
    
    if start_webui:
        try:
            from webui import run_server_in_thread
            run_server_in_thread(host=config.webui_host, port=config.webui_port)
            start_bot_stream_clients(config)
        except Exception as e:
            logger.error(f"å¯åŠ¨ WebUI å¤±è´¥: {e}")
    
    # === ä»… WebUI æ¨¡å¼ï¼šä¸è‡ªåŠ¨æ‰§è¡Œåˆ†æ ===
    if args.webui_only:
        logger.info("æ¨¡å¼: ä»… WebUI æœåŠ¡")
        logger.info(f"WebUI è¿è¡Œä¸­: http://{config.webui_host}:{config.webui_port}")
        logger.info("é€šè¿‡ /analysis?code=xxx æ¥å£æ‰‹åŠ¨è§¦å‘åˆ†æ")
        logger.info("æŒ‰ Ctrl+C é€€å‡º...")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        return 0

    try:
        # æ¨¡å¼1: ä»…å¤§ç›˜å¤ç›˜
        if args.market_review:
            logger.info("æ¨¡å¼: ä»…å¤§ç›˜å¤ç›˜")
            notifier = NotificationService()
            
            # åˆå§‹åŒ–æœç´¢æœåŠ¡å’Œåˆ†æå™¨ï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
            search_service = None
            analyzer = None
            
            if config.bocha_api_keys or config.tavily_api_keys or config.serpapi_keys:
                search_service = SearchService(
                    bocha_keys=config.bocha_api_keys,
                    tavily_keys=config.tavily_api_keys,
                    serpapi_keys=config.serpapi_keys
                )
            
            if config.gemini_api_key or config.openai_api_key:
                analyzer = GeminiAnalyzer(api_key=config.gemini_api_key)
                if not analyzer.is_available():
                    logger.warning("AI åˆ†æå™¨åˆå§‹åŒ–åä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ API Key é…ç½®")
                    analyzer = None
            else:
                logger.warning("æœªæ£€æµ‹åˆ° API Key (Gemini/OpenAI)ï¼Œå°†ä»…ä½¿ç”¨æ¨¡æ¿ç”ŸæˆæŠ¥å‘Š")
            
            run_market_review(
                notifier=notifier, 
                analyzer=analyzer, 
                search_service=search_service,
                send_notification=not args.no_notify
            )
            return 0
        
        # æ¨¡å¼2: å®šæ—¶ä»»åŠ¡æ¨¡å¼
        if args.schedule or config.schedule_enabled:
            logger.info("æ¨¡å¼: å®šæ—¶ä»»åŠ¡")
            logger.info(f"æ¯æ—¥æ‰§è¡Œæ—¶é—´: {config.schedule_time}")
            
            from src.scheduler import run_with_schedule
            
            def scheduled_task():
                run_full_analysis(config, args, stock_codes)
            
            run_with_schedule(
                task=scheduled_task,
                schedule_time=config.schedule_time,
                run_immediately=True  # å¯åŠ¨æ—¶å…ˆæ‰§è¡Œä¸€æ¬¡
            )
            return 0
        
        # æ¨¡å¼3: æ­£å¸¸å•æ¬¡è¿è¡Œ
        run_full_analysis(config, args, stock_codes)
        
        logger.info("\nç¨‹åºæ‰§è¡Œå®Œæˆ")
        
        # å¦‚æœå¯ç”¨äº† WebUI ä¸”æ˜¯éå®šæ—¶ä»»åŠ¡æ¨¡å¼ï¼Œä¿æŒç¨‹åºè¿è¡Œä»¥ä¾¿è®¿é—® WebUI
        if start_webui and not (args.schedule or config.schedule_enabled):
            logger.info("WebUI è¿è¡Œä¸­ (æŒ‰ Ctrl+C é€€å‡º)...")
            try:
                # ç®€å•çš„ä¿æŒæ´»è·ƒå¾ªç¯
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
        
        return 0
        
    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        return 130
        
    except Exception as e:
        logger.exception(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
