# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - å­˜å‚¨å±‚
===================================

èŒè´£ï¼š
1. ç®¡ç† SQLite æ•°æ®åº“è¿æ¥ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
2. å®šä¹‰ ORM æ•°æ®æ¨¡å‹
3. æä¾›æ•°æ®å­˜å–æ¥å£
4. å®ç°æ™ºèƒ½æ›´æ–°é€»è¾‘ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
"""

import atexit
import hashlib
import json
import logging
import re
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict, Any, TYPE_CHECKING
from pathlib import Path

import pandas as pd
from sqlalchemy import (
    create_engine,
    Column,
    String,
    Float,
    Date,
    DateTime,
    Integer,
    Index,
    UniqueConstraint,
    Text,
    select,
    and_,
    desc,
)
from sqlalchemy.orm import (
    declarative_base,
    sessionmaker,
    Session,
)
from sqlalchemy.exc import IntegrityError

from src.config import get_config

logger = logging.getLogger(__name__)

# SQLAlchemy ORM åŸºç±»
Base = declarative_base()

if TYPE_CHECKING:
    from src.search_service import SearchResponse


# === æ•°æ®æ¨¡å‹å®šä¹‰ ===

class StockDaily(Base):
    """
    è‚¡ç¥¨æ—¥çº¿æ•°æ®æ¨¡å‹
    
    å­˜å‚¨æ¯æ—¥è¡Œæƒ…æ•°æ®å’Œè®¡ç®—çš„æŠ€æœ¯æŒ‡æ ‡
    æ”¯æŒå¤šè‚¡ç¥¨ã€å¤šæ—¥æœŸçš„å”¯ä¸€çº¦æŸ
    """
    __tablename__ = 'stock_daily'
    
    # ä¸»é”®
    id = Column(Integer, primary_key=True, autoincrement=True)
    
    # è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 600519, 000001ï¼‰
    code = Column(String(10), nullable=False, index=True)
    
    # äº¤æ˜“æ—¥æœŸ
    date = Column(Date, nullable=False, index=True)
    
    # OHLC æ•°æ®
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    
    # æˆäº¤æ•°æ®
    volume = Column(Float)  # æˆäº¤é‡ï¼ˆè‚¡ï¼‰
    amount = Column(Float)  # æˆäº¤é¢ï¼ˆå…ƒï¼‰
    pct_chg = Column(Float)  # æ¶¨è·Œå¹…ï¼ˆ%ï¼‰
    
    # æŠ€æœ¯æŒ‡æ ‡
    ma5 = Column(Float)
    ma10 = Column(Float)
    ma20 = Column(Float)
    volume_ratio = Column(Float)  # é‡æ¯”
    
    # æ•°æ®æ¥æº
    data_source = Column(String(50))  # è®°å½•æ•°æ®æ¥æºï¼ˆå¦‚ AkshareFetcherï¼‰
    
    # æ›´æ–°æ—¶é—´
    created_at = Column(DateTime, default=datetime.now)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)
    
    # å”¯ä¸€çº¦æŸï¼šåŒä¸€è‚¡ç¥¨åŒä¸€æ—¥æœŸåªèƒ½æœ‰ä¸€æ¡æ•°æ®
    __table_args__ = (
        UniqueConstraint('code', 'date', name='uix_code_date'),
        Index('ix_code_date', 'code', 'date'),
    )
    
    def __repr__(self):
        return f"<StockDaily(code={self.code}, date={self.date}, close={self.close})>"
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'date': self.date,
            'open': self.open,
            'high': self.high,
            'low': self.low,
            'close': self.close,
            'volume': self.volume,
            'amount': self.amount,
            'pct_chg': self.pct_chg,
            'ma5': self.ma5,
            'ma10': self.ma10,
            'ma20': self.ma20,
            'volume_ratio': self.volume_ratio,
            'data_source': self.data_source,
        }


class NewsIntel(Base):
    """
    æ–°é—»æƒ…æŠ¥æ•°æ®æ¨¡å‹

    å­˜å‚¨æœç´¢åˆ°çš„æ–°é—»æƒ…æŠ¥æ¡ç›®ï¼Œç”¨äºåç»­åˆ†æä¸æŸ¥è¯¢
    """
    __tablename__ = 'news_intel'

    id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”ç”¨æˆ·æŸ¥è¯¢æ“ä½œ
    query_id = Column(String(64), index=True)

    # è‚¡ç¥¨ä¿¡æ¯
    code = Column(String(10), nullable=False, index=True)
    name = Column(String(50))

    # æœç´¢ä¸Šä¸‹æ–‡
    dimension = Column(String(32), index=True)  # latest_news / risk_check / earnings / market_analysis / industry
    query = Column(String(255))
    provider = Column(String(32), index=True)

    # æ–°é—»å†…å®¹
    title = Column(String(300), nullable=False)
    snippet = Column(Text)
    url = Column(String(1000), nullable=False)
    source = Column(String(100))
    published_date = Column(DateTime, index=True)

    # å…¥åº“æ—¶é—´
    fetched_at = Column(DateTime, default=datetime.now, index=True)
    query_source = Column(String(32), index=True)  # bot/web/cli/system
    requester_platform = Column(String(20))
    requester_user_id = Column(String(64))
    requester_user_name = Column(String(64))
    requester_chat_id = Column(String(64))
    requester_message_id = Column(String(64))
    requester_query = Column(String(255))

    __table_args__ = (
        UniqueConstraint('url', name='uix_news_url'),
        Index('ix_news_code_pub', 'code', 'published_date'),
    )

    def __repr__(self) -> str:
        return f"<NewsIntel(code={self.code}, title={self.title[:20]}...)>"


class AnalysisHistory(Base):
    """
    åˆ†æç»“æœå†å²è®°å½•æ¨¡å‹

    ä¿å­˜æ¯æ¬¡åˆ†æç»“æœï¼Œæ”¯æŒæŒ‰ query_id/è‚¡ç¥¨ä»£ç æ£€ç´¢
    """
    __tablename__ = 'analysis_history'

    id = Column(Integer, primary_key=True, autoincrement=True)

    # å…³è”æŸ¥è¯¢é“¾è·¯
    query_id = Column(String(64), index=True)

    # è‚¡ç¥¨ä¿¡æ¯
    code = Column(String(10), nullable=False, index=True)
    name = Column(String(50))
    report_type = Column(String(16), index=True)

    # æ ¸å¿ƒç»“è®º
    sentiment_score = Column(Integer)
    operation_advice = Column(String(20))
    trend_prediction = Column(String(50))
    analysis_summary = Column(Text)

    # è¯¦ç»†æ•°æ®
    raw_result = Column(Text)
    news_content = Column(Text)
    context_snapshot = Column(Text)

    # ç‹™å‡»ç‚¹ä½ï¼ˆç”¨äºå›æµ‹ï¼‰
    ideal_buy = Column(Float)
    secondary_buy = Column(Float)
    stop_loss = Column(Float)
    take_profit = Column(Float)

    created_at = Column(DateTime, default=datetime.now, index=True)

    __table_args__ = (
        Index('ix_analysis_code_time', 'code', 'created_at'),
    )

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'id': self.id,
            'query_id': self.query_id,
            'code': self.code,
            'name': self.name,
            'report_type': self.report_type,
            'sentiment_score': self.sentiment_score,
            'operation_advice': self.operation_advice,
            'trend_prediction': self.trend_prediction,
            'analysis_summary': self.analysis_summary,
            'raw_result': self.raw_result,
            'news_content': self.news_content,
            'context_snapshot': self.context_snapshot,
            'ideal_buy': self.ideal_buy,
            'secondary_buy': self.secondary_buy,
            'stop_loss': self.stop_loss,
            'take_profit': self.take_profit,
            'created_at': self.created_at.isoformat() if self.created_at else None,
        }


class DatabaseManager:
    """
    æ•°æ®åº“ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼
    
    èŒè´£ï¼š
    1. ç®¡ç†æ•°æ®åº“è¿æ¥æ± 
    2. æä¾› Session ä¸Šä¸‹æ–‡ç®¡ç†
    3. å°è£…æ•°æ®å­˜å–æ“ä½œ
    """
    
    _instance: Optional['DatabaseManager'] = None
    
    def __new__(cls, *args, **kwargs):
        """å•ä¾‹æ¨¡å¼å®ç°"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self, db_url: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_url: æ•°æ®åº“è¿æ¥ URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        if self._initialized:
            return
        
        if db_url is None:
            config = get_config()
            db_url = config.get_db_url()
        
        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        self._engine = create_engine(
            db_url,
            echo=False,  # è®¾ä¸º True å¯æŸ¥çœ‹ SQL è¯­å¥
            pool_pre_ping=True,  # è¿æ¥å¥åº·æ£€æŸ¥
        )
        
        # åˆ›å»º Session å·¥å‚
        self._SessionLocal = sessionmaker(
            bind=self._engine,
            autocommit=False,
            autoflush=False,
        )
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(self._engine)

        self._initialized = True
        logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_url}")

        # æ³¨å†Œé€€å‡ºé’©å­ï¼Œç¡®ä¿ç¨‹åºé€€å‡ºæ—¶å…³é—­æ•°æ®åº“è¿æ¥
        atexit.register(DatabaseManager._cleanup_engine, self._engine)
    
    @classmethod
    def get_instance(cls) -> 'DatabaseManager':
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    @classmethod
    def reset_instance(cls) -> None:
        """é‡ç½®å•ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        if cls._instance is not None:
            cls._instance._engine.dispose()
            cls._instance = None

    @classmethod
    def _cleanup_engine(cls, engine) -> None:
        """
        æ¸…ç†æ•°æ®åº“å¼•æ“ï¼ˆatexit é’©å­ï¼‰

        ç¡®ä¿ç¨‹åºé€€å‡ºæ—¶å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥ï¼Œé¿å… ResourceWarning

        Args:
            engine: SQLAlchemy å¼•æ“å¯¹è±¡
        """
        try:
            if engine is not None:
                engine.dispose()
                logger.debug("æ•°æ®åº“å¼•æ“å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†æ•°æ®åº“å¼•æ“æ—¶å‡ºé”™: {e}")
    
    def get_session(self) -> Session:
        """
        è·å–æ•°æ®åº“ Session
        
        ä½¿ç”¨ç¤ºä¾‹:
            with db.get_session() as session:
                # æ‰§è¡ŒæŸ¥è¯¢
                session.commit()  # å¦‚æœéœ€è¦
        """
        session = self._SessionLocal()
        try:
            return session
        except Exception:
            session.close()
            raise
    
    def has_today_data(self, code: str, target_date: Optional[date] = None) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        ç”¨äºæ–­ç‚¹ç»­ä¼ é€»è¾‘ï¼šå¦‚æœå·²æœ‰æ•°æ®åˆ™è·³è¿‡ç½‘ç»œè¯·æ±‚
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨æ•°æ®
        """
        if target_date is None:
            target_date = date.today()
        
        with self.get_session() as session:
            result = session.execute(
                select(StockDaily).where(
                    and_(
                        StockDaily.code == code,
                        StockDaily.date == target_date
                    )
                )
            ).scalar_one_or_none()
            
            return result is not None
    
    def get_latest_data(
        self, 
        code: str, 
        days: int = 2
    ) -> List[StockDaily]:
        """
        è·å–æœ€è¿‘ N å¤©çš„æ•°æ®
        
        ç”¨äºè®¡ç®—"ç›¸æ¯”æ˜¨æ—¥"çš„å˜åŒ–
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: è·å–å¤©æ•°
            
        Returns:
            StockDaily å¯¹è±¡åˆ—è¡¨ï¼ˆæŒ‰æ—¥æœŸé™åºï¼‰
        """
        with self.get_session() as session:
            results = session.execute(
                select(StockDaily)
                .where(StockDaily.code == code)
                .order_by(desc(StockDaily.date))
                .limit(days)
            ).scalars().all()
            
            return list(results)

    def save_news_intel(
        self,
        code: str,
        name: str,
        dimension: str,
        query: str,
        response: 'SearchResponse',
        query_context: Optional[Dict[str, str]] = None
    ) -> int:
        """
        ä¿å­˜æ–°é—»æƒ…æŠ¥åˆ°æ•°æ®åº“

        å»é‡ç­–ç•¥ï¼š
        - ä¼˜å…ˆæŒ‰ URL å»é‡ï¼ˆå”¯ä¸€çº¦æŸï¼‰
        - URL ç¼ºå¤±æ—¶æŒ‰ title + source + published_date è¿›è¡Œè½¯å»é‡

        å…³è”ç­–ç•¥ï¼š
        - query_context è®°å½•ç”¨æˆ·æŸ¥è¯¢ä¿¡æ¯ï¼ˆå¹³å°ã€ç”¨æˆ·ã€ä¼šè¯ã€åŸå§‹æŒ‡ä»¤ç­‰ï¼‰
        """
        if not response or not response.results:
            return 0

        saved_count = 0

        with self.get_session() as session:
            try:
                for item in response.results:
                    title = (item.title or '').strip()
                    url = (item.url or '').strip()
                    source = (item.source or '').strip()
                    snippet = (item.snippet or '').strip()
                    published_date = self._parse_published_date(item.published_date)

                    if not title and not url:
                        continue

                    url_key = url or self._build_fallback_url_key(
                        code=code,
                        title=title,
                        source=source,
                        published_date=published_date
                    )

                    # ä¼˜å…ˆæŒ‰ URL æˆ–å…œåº•é”®å»é‡
                    existing = session.execute(
                        select(NewsIntel).where(NewsIntel.url == url_key)
                    ).scalar_one_or_none()

                    if existing:
                        existing.name = name or existing.name
                        existing.dimension = dimension or existing.dimension
                        existing.query = query or existing.query
                        existing.provider = response.provider or existing.provider
                        existing.snippet = snippet or existing.snippet
                        existing.source = source or existing.source
                        existing.published_date = published_date or existing.published_date
                        existing.fetched_at = datetime.now()

                        if query_context:
                            existing.query_id = query_context.get("query_id") or existing.query_id
                            existing.query_source = query_context.get("query_source") or existing.query_source
                            existing.requester_platform = query_context.get("requester_platform") or existing.requester_platform
                            existing.requester_user_id = query_context.get("requester_user_id") or existing.requester_user_id
                            existing.requester_user_name = query_context.get("requester_user_name") or existing.requester_user_name
                            existing.requester_chat_id = query_context.get("requester_chat_id") or existing.requester_chat_id
                            existing.requester_message_id = query_context.get("requester_message_id") or existing.requester_message_id
                            existing.requester_query = query_context.get("requester_query") or existing.requester_query
                    else:
                        try:
                            with session.begin_nested():
                                record = NewsIntel(
                                    code=code,
                                    name=name,
                                    dimension=dimension,
                                    query=query,
                                    provider=response.provider,
                                    title=title,
                                    snippet=snippet,
                                    url=url_key,
                                    source=source,
                                    published_date=published_date,
                                    fetched_at=datetime.now(),
                                    query_id=(query_context or {}).get("query_id"),
                                    query_source=(query_context or {}).get("query_source"),
                                    requester_platform=(query_context or {}).get("requester_platform"),
                                    requester_user_id=(query_context or {}).get("requester_user_id"),
                                    requester_user_name=(query_context or {}).get("requester_user_name"),
                                    requester_chat_id=(query_context or {}).get("requester_chat_id"),
                                    requester_message_id=(query_context or {}).get("requester_message_id"),
                                    requester_query=(query_context or {}).get("requester_query"),
                                )
                                session.add(record)
                                session.flush()
                            saved_count += 1
                        except IntegrityError:
                            # å•æ¡ URL å”¯ä¸€çº¦æŸå†²çªï¼ˆå¦‚å¹¶å‘æ’å…¥ï¼‰ï¼Œä»…è·³è¿‡æœ¬æ¡ï¼Œä¿ç•™æœ¬æ‰¹å…¶ä½™æˆåŠŸé¡¹
                            logger.debug("æ–°é—»æƒ…æŠ¥é‡å¤ï¼ˆå·²è·³è¿‡ï¼‰: %s %s", code, url_key)

                session.commit()
                logger.info(f"ä¿å­˜æ–°é—»æƒ…æŠ¥æˆåŠŸ: {code}, æ–°å¢ {saved_count} æ¡")

            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜æ–°é—»æƒ…æŠ¥å¤±è´¥: {e}")
                raise

        return saved_count

    def get_recent_news(self, code: str, days: int = 7, limit: int = 20) -> List[NewsIntel]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ N å¤©çš„æ–°é—»æƒ…æŠ¥
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            results = session.execute(
                select(NewsIntel)
                .where(
                    and_(
                        NewsIntel.code == code,
                        NewsIntel.fetched_at >= cutoff_date
                    )
                )
                .order_by(desc(NewsIntel.fetched_at))
                .limit(limit)
            ).scalars().all()

            return list(results)

    def save_analysis_history(
        self,
        result: Any,
        query_id: str,
        report_type: str,
        news_content: Optional[str],
        context_snapshot: Optional[Dict[str, Any]] = None,
        save_snapshot: bool = True
    ) -> int:
        """
        ä¿å­˜åˆ†æç»“æœå†å²è®°å½•
        """
        if result is None:
            return 0

        sniper_points = self._extract_sniper_points(result)
        raw_result = self._build_raw_result(result)
        context_text = None
        if save_snapshot and context_snapshot is not None:
            context_text = self._safe_json_dumps(context_snapshot)

        record = AnalysisHistory(
            query_id=query_id,
            code=result.code,
            name=result.name,
            report_type=report_type,
            sentiment_score=result.sentiment_score,
            operation_advice=result.operation_advice,
            trend_prediction=result.trend_prediction,
            analysis_summary=result.analysis_summary,
            raw_result=self._safe_json_dumps(raw_result),
            news_content=news_content,
            context_snapshot=context_text,
            ideal_buy=sniper_points.get("ideal_buy"),
            secondary_buy=sniper_points.get("secondary_buy"),
            stop_loss=sniper_points.get("stop_loss"),
            take_profit=sniper_points.get("take_profit"),
            created_at=datetime.now(),
        )

        with self.get_session() as session:
            try:
                session.add(record)
                session.commit()
                return 1
            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜åˆ†æå†å²å¤±è´¥: {e}")
                return 0

    def get_analysis_history(
        self,
        code: Optional[str] = None,
        query_id: Optional[str] = None,
        days: int = 30,
        limit: int = 50
    ) -> List[AnalysisHistory]:
        """
        æŸ¥è¯¢åˆ†æå†å²è®°å½•
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            conditions = [AnalysisHistory.created_at >= cutoff_date]
            if code:
                conditions.append(AnalysisHistory.code == code)
            if query_id:
                conditions.append(AnalysisHistory.query_id == query_id)

            results = session.execute(
                select(AnalysisHistory)
                .where(and_(*conditions))
                .order_by(desc(AnalysisHistory.created_at))
                .limit(limit)
            ).scalars().all()

            return list(results)
    
    def get_data_range(
        self, 
        code: str, 
        start_date: date, 
        end_date: date
    ) -> List[StockDaily]:
        """
        è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            StockDaily å¯¹è±¡åˆ—è¡¨
        """
        with self.get_session() as session:
            results = session.execute(
                select(StockDaily)
                .where(
                    and_(
                        StockDaily.code == code,
                        StockDaily.date >= start_date,
                        StockDaily.date <= end_date
                    )
                )
                .order_by(StockDaily.date)
            ).scalars().all()
            
            return list(results)
    
    def save_daily_data(
        self, 
        df: pd.DataFrame, 
        code: str,
        data_source: str = "Unknown"
    ) -> int:
        """
        ä¿å­˜æ—¥çº¿æ•°æ®åˆ°æ•°æ®åº“
        
        ç­–ç•¥ï¼š
        - ä½¿ç”¨ UPSERT é€»è¾‘ï¼ˆå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥ï¼‰
        - è·³è¿‡å·²å­˜åœ¨çš„æ•°æ®ï¼Œé¿å…é‡å¤
        
        Args:
            df: åŒ…å«æ—¥çº¿æ•°æ®çš„ DataFrame
            code: è‚¡ç¥¨ä»£ç 
            data_source: æ•°æ®æ¥æºåç§°
            
        Returns:
            æ–°å¢/æ›´æ–°çš„è®°å½•æ•°
        """
        if df is None or df.empty:
            logger.warning(f"ä¿å­˜æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ {code}")
            return 0
        
        saved_count = 0
        
        with self.get_session() as session:
            try:
                for _, row in df.iterrows():
                    # è§£ææ—¥æœŸ
                    row_date = row.get('date')
                    if isinstance(row_date, str):
                        row_date = datetime.strptime(row_date, '%Y-%m-%d').date()
                    elif isinstance(row_date, datetime):
                        row_date = row_date.date()
                    elif isinstance(row_date, pd.Timestamp):
                        row_date = row_date.date()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = session.execute(
                        select(StockDaily).where(
                            and_(
                                StockDaily.code == code,
                                StockDaily.date == row_date
                            )
                        )
                    ).scalar_one_or_none()
                    
                    if existing:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        existing.open = row.get('open')
                        existing.high = row.get('high')
                        existing.low = row.get('low')
                        existing.close = row.get('close')
                        existing.volume = row.get('volume')
                        existing.amount = row.get('amount')
                        existing.pct_chg = row.get('pct_chg')
                        existing.ma5 = row.get('ma5')
                        existing.ma10 = row.get('ma10')
                        existing.ma20 = row.get('ma20')
                        existing.volume_ratio = row.get('volume_ratio')
                        existing.data_source = data_source
                        existing.updated_at = datetime.now()
                    else:
                        # åˆ›å»ºæ–°è®°å½•
                        record = StockDaily(
                            code=code,
                            date=row_date,
                            open=row.get('open'),
                            high=row.get('high'),
                            low=row.get('low'),
                            close=row.get('close'),
                            volume=row.get('volume'),
                            amount=row.get('amount'),
                            pct_chg=row.get('pct_chg'),
                            ma5=row.get('ma5'),
                            ma10=row.get('ma10'),
                            ma20=row.get('ma20'),
                            volume_ratio=row.get('volume_ratio'),
                            data_source=data_source,
                        )
                        session.add(record)
                        saved_count += 1
                
                session.commit()
                logger.info(f"ä¿å­˜ {code} æ•°æ®æˆåŠŸï¼Œæ–°å¢ {saved_count} æ¡")
                
            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜ {code} æ•°æ®å¤±è´¥: {e}")
                raise
        
        return saved_count
    
    def get_analysis_context(
        self, 
        code: str,
        target_date: Optional[date] = None
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–åˆ†ææ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®
        
        è¿”å›ä»Šæ—¥æ•°æ® + æ˜¨æ—¥æ•°æ®çš„å¯¹æ¯”ä¿¡æ¯
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰
            
        Returns:
            åŒ…å«ä»Šæ—¥æ•°æ®ã€æ˜¨æ—¥å¯¹æ¯”ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        if target_date is None:
            target_date = date.today()
        
        # è·å–æœ€è¿‘2å¤©æ•°æ®
        recent_data = self.get_latest_data(code, days=2)
        
        if not recent_data:
            logger.warning(f"æœªæ‰¾åˆ° {code} çš„æ•°æ®")
            return None
        
        today_data = recent_data[0]
        yesterday_data = recent_data[1] if len(recent_data) > 1 else None
        
        context = {
            'code': code,
            'date': today_data.date.isoformat(),
            'today': today_data.to_dict(),
        }
        
        if yesterday_data:
            context['yesterday'] = yesterday_data.to_dict()
            
            # è®¡ç®—ç›¸æ¯”æ˜¨æ—¥çš„å˜åŒ–
            if yesterday_data.volume and yesterday_data.volume > 0:
                context['volume_change_ratio'] = round(
                    today_data.volume / yesterday_data.volume, 2
                )
            
            if yesterday_data.close and yesterday_data.close > 0:
                context['price_change_ratio'] = round(
                    (today_data.close - yesterday_data.close) / yesterday_data.close * 100, 2
                )
            
            # å‡çº¿å½¢æ€åˆ¤æ–­
            context['ma_status'] = self._analyze_ma_status(today_data)
        
        return context
    
    def _analyze_ma_status(self, data: StockDaily) -> str:
        """
        åˆ†æå‡çº¿å½¢æ€
        
        åˆ¤æ–­æ¡ä»¶ï¼š
        - å¤šå¤´æ’åˆ—ï¼šclose > ma5 > ma10 > ma20
        - ç©ºå¤´æ’åˆ—ï¼šclose < ma5 < ma10 < ma20
        - éœ‡è¡æ•´ç†ï¼šå…¶ä»–æƒ…å†µ
        """
        close = data.close or 0
        ma5 = data.ma5 or 0
        ma10 = data.ma10 or 0
        ma20 = data.ma20 or 0
        
        if close > ma5 > ma10 > ma20 > 0:
            return "å¤šå¤´æ’åˆ— ğŸ“ˆ"
        elif close < ma5 < ma10 < ma20 and ma20 > 0:
            return "ç©ºå¤´æ’åˆ— ğŸ“‰"
        elif close > ma5 and ma5 > ma10:
            return "çŸ­æœŸå‘å¥½ ğŸ”¼"
        elif close < ma5 and ma5 < ma10:
            return "çŸ­æœŸèµ°å¼± ğŸ”½"
        else:
            return "éœ‡è¡æ•´ç† â†”ï¸"

    @staticmethod
    def _parse_published_date(value: Optional[str]) -> Optional[datetime]:
        """
        è§£æå‘å¸ƒæ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¤±è´¥è¿”å› Noneï¼‰
        """
        if not value:
            return None

        if isinstance(value, datetime):
            return value

        text = str(value).strip()
        if not text:
            return None

        # ä¼˜å…ˆå°è¯• ISO æ ¼å¼
        try:
            return datetime.fromisoformat(text)
        except ValueError:
            pass

        for fmt in (
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y/%m/%d %H:%M:%S",
            "%Y/%m/%d %H:%M",
            "%Y/%m/%d",
        ):
            try:
                return datetime.strptime(text, fmt)
            except ValueError:
                continue

        return None

    @staticmethod
    def _safe_json_dumps(data: Any) -> str:
        """
        å®‰å…¨åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²
        """
        try:
            return json.dumps(data, ensure_ascii=False, default=str)
        except Exception:
            return json.dumps(str(data), ensure_ascii=False)

    @staticmethod
    def _build_raw_result(result: Any) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´åˆ†æç»“æœå­—å…¸
        """
        data = result.to_dict() if hasattr(result, "to_dict") else {}
        data.update({
            'data_sources': getattr(result, 'data_sources', ''),
            'raw_response': getattr(result, 'raw_response', None),
        })
        return data

    @staticmethod
    def _parse_sniper_value(value: Any) -> Optional[float]:
        """
        è§£æç‹™å‡»ç‚¹ä½æ•°å€¼
        """
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)

        text = str(value).replace(',', '').strip()
        if not text:
            return None

        match = re.search(r"-?\d+(?:\.\d+)?", text)
        if not match:
            return None
        try:
            return float(match.group())
        except ValueError:
            return None

    def _extract_sniper_points(self, result: Any) -> Dict[str, Optional[float]]:
        """
        æŠ½å–ç‹™å‡»ç‚¹ä½æ•°æ®
        """
        raw_points = {}
        if hasattr(result, "get_sniper_points"):
            raw_points = result.get_sniper_points() or {}

        return {
            "ideal_buy": self._parse_sniper_value(raw_points.get("ideal_buy")),
            "secondary_buy": self._parse_sniper_value(raw_points.get("secondary_buy")),
            "stop_loss": self._parse_sniper_value(raw_points.get("stop_loss")),
            "take_profit": self._parse_sniper_value(raw_points.get("take_profit")),
        }

    @staticmethod
    def _build_fallback_url_key(
        code: str,
        title: str,
        source: str,
        published_date: Optional[datetime]
    ) -> str:
        """
        ç”Ÿæˆæ—  URL æ—¶çš„å»é‡é”®ï¼ˆç¡®ä¿ç¨³å®šä¸”è¾ƒçŸ­ï¼‰
        """
        date_str = published_date.isoformat() if published_date else ""
        raw_key = f"{code}|{title}|{source}|{date_str}"
        digest = hashlib.md5(raw_key.encode("utf-8")).hexdigest()
        return f"no-url:{code}:{digest}"


# ä¾¿æ·å‡½æ•°
def get_db() -> DatabaseManager:
    """è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹çš„å¿«æ·æ–¹å¼"""
    return DatabaseManager.get_instance()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    db = get_db()
    
    print("=== æ•°æ®åº“æµ‹è¯• ===")
    print(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æ£€æŸ¥ä»Šæ—¥æ•°æ®
    has_data = db.has_today_data('600519')
    print(f"èŒ…å°ä»Šæ—¥æ˜¯å¦æœ‰æ•°æ®: {has_data}")
    
    # æµ‹è¯•ä¿å­˜æ•°æ®
    test_df = pd.DataFrame({
        'date': [date.today()],
        'open': [1800.0],
        'high': [1850.0],
        'low': [1780.0],
        'close': [1820.0],
        'volume': [10000000],
        'amount': [18200000000],
        'pct_chg': [1.5],
        'ma5': [1810.0],
        'ma10': [1800.0],
        'ma20': [1790.0],
        'volume_ratio': [1.2],
    })
    
    saved = db.save_daily_data(test_df, '600519', 'TestSource')
    print(f"ä¿å­˜æµ‹è¯•æ•°æ®: {saved} æ¡")
    
    # æµ‹è¯•è·å–ä¸Šä¸‹æ–‡
    context = db.get_analysis_context('600519')
    print(f"åˆ†æä¸Šä¸‹æ–‡: {context}")
